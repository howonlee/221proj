\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[margin=1.5in]{geometry}

\usepackage{hyperref}

\begin{document}
\title{CS221 Project}
\author{Howon Lee}
\maketitle
\section*{Real-Time Note Recommendation}

\subsection*{Problem Definition}
A system was made to try and predict a good next pitch to play within 12 possible tones in real time, given a training set of notes. Basically, a probability distribution was made out of a training set of notes and we tried to predict such that, if a person took the "predicted" pitches, they would play from a similar probability distribution.
The data had to be gathered from a real piano player playing, so I got a piano player to create the training data and test out the system.

\subsection*{Challenges And Unproductive Approaches}
This is definitely something that must run in real-time, since ideally, the system would be used in real-time.
Actually quite hard as a task, given that I actually don't have any domain expertise that I knew about.
Non-laplace smoothing didn't make qualitative or quantitative difference, even thought I thought it would.

\subsection*{Hypothesis}
These are the hypotheses about the system that I made with reference to the problem statement and that I could test with experiments.
\begin{enumerate}
    \item The predictor will do better than random
    \item The predictor will also do better than prediction from non-appropriate data (JS Bach)
    \item The model matters in prediction task (qualitative, quantitative results)
\end{enumerate}
So I have to test the predictor versus random, the predictor versus prediction from a non-appropriate dataset, and I have to compare the models in the prediction task in two ways: qualitative and quantitative.

\subsection*{Methods}
Training dataset: stored notes from a piano player playing, also JS Bach.
Test dataset: the same piano player playing something different, extempore. Since the core task of the system seems to be predicting the pitches themselves, irrespective to which octave they were in, the predictions are measured by whether they are the correct pitch, but irrespective of octave: that is, if we were supposed to get an F4 (according to the piano player's next note), and we actually got an F5, that was counted as correct.
The piano player could not see the predictions that the system makes in either case, because the test set would not be a very good measure of the goodness of the prediction that way.

Probability distributions were Laplace smoothed with $\alpha = 0.05$ before normalization.

For a baseline, a Markov model (2-gram) was used, along with another, higher-order Markov model (3-gram).

\subsubsection*{Hidden Markov Model State}
Observed states are notes in HMM.
Hidden states were tried:
1. Previous note, because that could be construed as a hidden state, really
2. First note of 4-note run, because it seemed that a lot of four-note runs produce a certain class of those short sequences (licks)
3. Difference between previous note, because, although it was normalized, a tritone sounds much the same anywhere.

Forward-backwards training was used. Predictions were made by Viterbi, no variations on these because the training method itself shouldn't mess things up too bad: it was fast enough for the current system

\subsubsection*{Reinforcement Learning State}
Q-learning was done with epsilon-greedy method.
1. Previous note.
2. Difference between previous note.
Did not try first note of 4-note run because it seemed that this corresponded to a hidden state only, whereas it was plausible that the previous note and difference between previous note also corresponded to an observable state

\subsection*{Results and Analysis}
Note that the statistical tests to verify or falsify the null hypothesis with respect to distributions was the Kolmogorov-Smirnov test, so if I say "significant", I mean, "significant with respect to the KS test".

Hypothesis I should be sustained, because there was a statistically significant difference between the accuracy and average F1 scores (by class) of the model predictions and the JSB data. There is also a significant difference between the accuracy and average F1 scores of the model predictions and what would be predicted for random predictions drawn from a uniform probability distribution over the 12 possible tones.
Hypothesis II not sustained for quantitative (accuracy measure on prediction), because there was not a significant difference between the models.
However, qualitative (which predictions they did make), did make a difference. Here, once can tell this by visual inspection of the confusion matrices of some of the models. To wit, the models got most things wrong, but it got those things wrong in different ways.

\subsection*{Conclusion}
A predictor for real-time note recommendation was made.
Although it was not incredible accurate, it was better than random.
A variety of models were considered.
These different models did not have a quantitative difference but they did have a qualitative difference on the predictions made.

Try the program out to see the qualitative difference, if you wish.

\subsection*{Acknowledgement}
Thanks to J. Li, who made the training and test data by playing the keyboard program.

\begin{thebibliography}{9}

\bibitem{KneserNey}
Ney, H., et al., On Structuring Probabilistic Dependences in Stochastic Language Modeling, in Computer, Speech and Language, 1994

\bibitem{Goodman}
Goodman, J., A Bit of Progress in Language Modeling, in Computer Speech and Language, 2001

\bibitem{JSymbolic}
McKay, C., and Fujinaga, I., jSymbolic: A Feature Extractor for MIDI Files, in Proceedings of the International Computer Music Conference, 2006

\bibitem{Katz}
Katz, S. M., Estimation of Probabilities from Sparse Data for the Language Model Component of a Speech Recognizer, in IEEE Transactions on Acoustics, Speech and Signal Processing, 1987

\bibitem{BoulangerLewandowski12}
N Boulanger-Lewandowsky, Y. Bengio and P. Vincent, Modeling Temporal Dependencies in High-Dimensional Sequences: Application to Polyphonic Music Generation and Transcription, in Proceedings of the 29th International Conference on Machine Learning (ICML), 2012.

\bibitem{Rabiner}
L. Rabiner, A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition, in Proceeding of the IEEE, 1989.

\bibitem{Watkins}
C. Watkins, Technical Note on Q-Learning, in Machine Learning, 1992.

\bibitem{Rummery}
N. Taghipour, A. Kardan, A Hybrid Web Recommender System Based on Q-Learning, in the 8th ACM Sympsium on Applied Computing, 2008

\bibitem{Schulze}
Schulze, W., and van der Merwe, B., Music Generation with Markov Models, in MultiMedia, IEEE, 2011

\end{thebibliography}

\end{document}
