\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[margin=1.5in]{geometry}

\usepackage{hyperref}

\begin{document}
\title{CS221 Project}
\author{Howon Lee}
\maketitle
\section*{Real-Time Note Recommendation}

\subsection*{Problem Definition}
Want to do this out of interest in music.
Given previous set of notes, predict a next tone within 12 possible tones in real time.
Predictions taken as drawing from a probability distribution. We want to know a good way to figure out the probability distribution.
Want to do this real-time as perhaps a system for the person playing in realtime.
Also want a real piano player's opinion on this, so I got J. Li

\subsection*{Challenges And Unproductive Approaches}
Actually quite hard as a task, given that I actually don't have any domain expertise that I knew about.
I thought RBM would be a fairly interesting way of going about things, because it should be something like a good graphical method that would cluster things. RBM didn't work so well, too slow
Non-laplace smoothing didn't make qualitative or quantitative difference, even thought I thought it would.

\subsection*{Hypothesis}
Testable hypotheses
\begin{enumerate}
    \item The predictor will do better than random
    \item The predictor will also do better than prediction from non-appropriate data (JS Bach)
    \item The model matters in prediction task (qualitative, quantitative results)
\end{enumerate}
So I have to test the predictor versus random, the predictor versus prediction from a non-appropriate dataset, and I have to compare the models in the prediction task in two ways: qualitative and quantitative.

\subsection*{Methods}
Training dataset: stored notes from a piano player playing, also JS Bach.
Test dataset: the same piano player playing something different, extempore. %%how much data, what data, the 12 notes, etc
The piano player could not see the predictions that the system makes in either case, because the test set would be silly otherwise. I tried showing it, and basically they just followed the prediction, no matter how silly it was.

Probability distributions were Laplace smoothed with $\alpha = 0.05$.

Markov Model: states are notes, to be used as baseline. I also did a higher-order Markov Model, to see if that helped, because it might be the case that more memory could 

\subsubsection*{Hidden Markov Model State}
Observed states are notes in HMM.
Hidden states were tried:
1. Previous note, because that could be construed as a hidden state, really
2. First note of 4-note run, because it seemed that a lot of four-note runs produce a certain class of those short sequences (licks)
3. Difference between previous note, because, although it was normalized, a tritone sounds much the same anywhere.

Trained forward-backwards. Predictions made by Viterbi, no variations on these because the training method itself shouldn't mess things up too bad: it was fast enough for the current system

\subsubsection*{Reinforcement Learning State}
Q-learning was done with epsilong-greedy method. Epsilon was 0.1, alpha was 0.2, gamma was 0.9. %%%explain what those are, why those
1. Previous note.
2. Difference between previous note.
Did not try first note of 4-note run because it seemed that this corresponded to a hidden state only, whereas it was plausible that the previous note and difference between previous note also corresponded to an observable state

\subsection*{Results and Analysis}
Note that the statistical tests to verify or falsify the null hypothesis with respect to distributions was the Kolmogorov-Smirnov test. %%%figure out doing it properly

Hypothesis I sustained, because there was a statistically significant difference between the accuracy and average F1 scores (by class) of the model predictions and the JSB data. There is also a statistically significantly significant difference between the accuracy and average F1 scores of the model predictions and what would be predicted for random predictions drawn from a uniform probability distribution over the 12 possible tones. %datadatadata
Hypothesis II not sustained for quantitative (accuracy measure on prediction), because there was not a significant difference between the models. %datattatatatat
However, qualitative (which predictions they did make), did make a difference. Here, once can tell this by visual inspection of the confusion matrices of some of the models. To wit, the models got most things wrong, but it got those things wrong in different ways.

\subsection*{Conclusion}
A predictor for real-time note recommendation was made.
Although it was not incredible accurate, it was better than random.
A variety of models were considered.
These different models did not have a quantitative difference but they did have a qualitative difference on the predictions made.

Try the program out to see the qualitative difference, if you wish.

\subsection*{Acknowledgement}
Thanks to J. Li, who made the training and test data by playing the keyboard program.

\begin{thebibliography}{9}%no more than 9 references

\bibitem{KneserNey}
Ney, H., et al., On Structuring Probabilistic Dependences in Stochastic Language Modeling, in Computer, Speech and Language, 1994

\bibitem{Goodman}
Goodman, J., A Bit of Progress in Language Modeling, in Computer Speech and Language, 2001

\bibitem{JSymbolic}
McKay, C., and Fujinaga, I., jSymbolic: A Feature Extractor for MIDI Files, in Proceedings of the International Computer Music Conference, 2006

\bibitem{Katz}
Katz, S. M., Estimation of Probabilities from Sparse Data for the Language Model Component of a Speech Recognizer, in IEEE Transactions on Acoustics, Speech and Signal Processing, 1987

\bibitem{BoulangerLewandowski12}
N Boulanger-Lewandowsky, Y. Bengio and P. Vincent, Modeling Temporal Dependencies in High-Dimensional Sequences: Application to Polyphonic Music Generation and Transcription, in Proceedings of the 29th International Conference on Machine Learning (ICML), 2012.

\bibitem{Rabiner}
L. Rabiner, A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition, in Proceeding of the IEEE, 1989.

\bibitem{Watkins}
C. Watkins, Technical Note on Q-Learning, in Machine Learning, 1992.

\bibitem{Rummery}
N. Taghipour, A. Kardan, A Hybrid Web Recommender System Based on Q-Learning, in the 8th ACM Sympsium on Applied Computing, 2008

\bibitem{Schulze}
Schulze, W., and van der Merwe, B., Music Generation with Markov Models, in MultiMedia, IEEE, 2011

\end{thebibliography}

\end{document}
