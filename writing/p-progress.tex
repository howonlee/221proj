\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[margin=1.0in]{geometry}

\usepackage{hyperref}

\begin{document}
\title{project proposal}
\author{howon lee}
\maketitle
\section*{Note recommendation for the musician in performance}

\begin{figure}
\begin{tabular}{c | c c c c c c c c c c c c c}
 & C4 & C\# & D & D\# & E & F & F\# & G & G\# & A & A\# & B & C5\\
\hline
C4 & 19 & 0 & 0 & 0 & 0 & 4 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
C\# & 3  & 0 & 0 & 0 & 0 & 2 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
D & 23 & 0 & 0 & 0 & 0 & 2 & 0 & 0 & 3 & 0 & 0 & 0 & 0\\
D\# & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
E & 0 & 0 & 0 & 0 & 3 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
F & 0 & 0 & 0 & 0 & 7 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
F#  & 0 & 0 & 0 & 0 & 2 & 0 & 0 & 3 & 0 & 0 & 0 & 0\\
G & 0 & 0 & 0 & 0 & 7 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
G\#  & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
A & 0 & 0 & 0 & 0 & 6 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
A\#  & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
B & 0 & 0 & 0 & 0 & 3 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
C5 & 0 & 0 & 0 & 0 & 3 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
\end{tabular}
\caption{Confusion matrix for a piano player on NB classifier}
\end{figure}

\subsection*{Task Definition}
The system will take in computer keyboard input and play music as if it were a MIDI keyboard. This by itself is not too terribly impressive, but what it should also do is to give suggestions in real-time for what notes to play, for the player who want a little bit of help improvising.

There are two ways of looking at the task there: perhaps it is giving suggestions in real-time for what notes to play based upon a corpus of stored MIDI music data, in which case the actual task would be time series generation. Or perhaps it is being rewarded or punished by the person at the keyboard playing its notes, in which case it would be doing reinforcement learning.

In either case, it seems to me that the best measurement for the success of the system will be the percentage of time that the person at the keyboard plays notes in accordance with the suggestions. If we look at the task as a time series generation, that ends up being the percentage of time that the person at the keyboard is in accordance with the generated time series. Of course there has to also be a large qualitative component in the actual aesthetics of what such a system generates, but this is what we can put on a chart. 

\subsection*{Hypothesis}
It seems to be the case that the closest analogy to this task is word-completion or word-modelling in a small-vocabulary space. This is because the musical notes can be seen to be the characters of words, or musical phrases seen to be words entire. This task also seems amenable to the Markov property, in that the extremely long-distance correlations between notes, while there may be a case made that they exist, seem to me to be weak. Therefore, there should be two hypotheses which can
be tested:

\begin{enumerate}
    \item It is the case that the models that people use for word-completion will work for this task.
    \item It is the case that the Markov property applies to the model for this task.
\end{enumerate}

To test the full assumptions behind the first hypothesis is too big a task, so what I will actually investigate for the first task is whether the Kneser-Ney smoothing give us better performance for this task than other smoothing methods. This is because the theoretical guarantees for Kneser-Ney smoothing models are based upon \emph{language} modelling.

\subsection*{Baseline System}
I have implemented the keyboard music part of the system. I will be using the pre-cleaned piano-roll MIDI files from the LISA lab found here:

\url{http://www-etud.iro.umontreal.ca/~boulanni/icml2012}

In order to test this, I got a piano player friend of mine to play it in the current incarnation.

For a baseline, I just set up a multinomial Naive Bayes classifier to choose the best note prediction, given the previous notes. The performance was not good: the classifier on the JS Bach dataset only predicted that the next note would be C, F or G sharp(see the confusion matrix for details).

Features for the system are listed in the table. %%%%%%%%%

%%%This is understandable, as there is no attempt to model any attribute of what the player's doing, and no state which is remembered. This system also only predicts the next note to play, where there should be information about the time, the rhythm, and things of that nature.

\subsection*{Further Development}
The features I am implementing are 

\subsection*{Evaluation And Conclusion}

Currently, the point that's giving me trouble are connecting the feature extraction to the algorithms I'm making.

You can keep track of the development at github:

\url{https://github.com/howonlee/221proj}

\begin{thebibliography}{9}%no more than 9 references

\bibitem{BoulangerLewandowski12}
N Boulanger-Lewandowsky, Y. Bengio and P. Vincent, Modeling Temporal Dependencies in High-Dimensional Sequences: Application to Polyphonic Music Generation and Transcription, in Proceedings of the 29th International Conference on Machine Learning (ICML), 2012.

\bibitem{Rabiner}
L. Rabiner, A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition, in Proceeding of the IEEE, 1989.

\bibitem{Watkins}
C. Watkins, Technical Note on Q-Learning, in Machine Learning, 1992.

\bibitem{Rummery}
N. Taghipour, A. Kardan, A Hybrid Web Recommender System Based on Q-Learning, in the 8th ACM Sympsium on Applied Computing, 2008

\end{thebibliography}

\end{document}
