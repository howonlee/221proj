\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[margin=1.0in]{geometry}

\usepackage{hyperref}

\begin{document}
\title{project progress}
\author{howon lee}
\maketitle
\section*{Note recommendation for the musician in performance}

\subsection*{Task Definition}
The system will take in computer keyboard input and play music as if it were a MIDI keyboard. This by itself is not too terribly impressive, but what it should also do is to give suggestions in real-time for what notes to play, for the player who want a little bit of help improvising.

There are two ways of looking at the task there: perhaps it is giving suggestions in real-time for what notes to play based upon a corpus of stored MIDI music data, in which case the actual task would be time series generation. Or perhaps it is being rewarded or punished by the person at the keyboard playing its notes, in which case it would be doing reinforcement learning.

In either case, it seems to me that the best measurement for the success of the system will be the percentage of time that the person at the keyboard plays notes in accordance with the suggestions. If we look at the task as a time series generation, that ends up being the percentage of time that the person at the keyboard is in accordance with the generated time series. Of course there has to also be a large qualitative component in the actual aesthetics of what such a system generates, but this is what we can put on a chart. 

\subsection*{Hypothesis}
It seems to be the case that the closest analogy to this task is word-completion or word-modelling in a small-vocabulary space. This is because the musical notes can be seen to be the characters of words, or musical phrases seen to be words entire. This task also seems amenable to inclusion under the reinforcement learning paradigm, because it seems that the actual behavior of the player is important as a feedback mechanism. Therefore, there should be two hypotheses which can
be tested:

\begin{enumerate}
    \item It is the case that the models that people use for word-completion will work for this task.
    \item It is the case that reinforcment learning is a good AI paradigm for the task.
\end{enumerate}

To test the full assumptions behind the first hypothesis is too big a task, so what I will actually investigate for the first task is whether the Kneser-Ney smoothing give us better performance for this task than other smoothing methods. This is because the theoretical guarantees for Kneser-Ney smoothing models are based upon \emph{language} modelling.

The baseline here in both cases will be the unsmoothed HMM taught using EM. 

By "Kneser-Ney smoothing", I mean the interpolated Kneser-Ney smoothing. This is the model which combine both the higher-order and lower-order distributions. This I will compare with no smoothing, additive smoothing, Katz smoothing and Jelinek-Mercer smoothing.

By "Q-learning", I mean the model-free reinforcement learning technique. It seems tenable to back Q-learning with a table, since the state space for this model will not be complicated.

\subsection*{Baseline System}
I have implemented the keyboard music part of the system. I will be using the pre-cleaned piano-roll MIDI files from the LISA lab found here:

\url{http://www-etud.iro.umontreal.ca/~boulanni/icml2012}

Previously, I thought that Naive Bayes would do as a baseline, but the performance was so terrible (the classifier only predicted that the next note would be C, F or G all the time), that I will switch the baseline. For a baseline, I set up a HMM model to choose the best note prediction, learned by EM.

\subsection*{Further Development}
In comparing language models, I am doing a simple 3-gram feature of the note pitch values, taking the pre-cleaned data, which is always transposed to C major. The way that I am testing the assumption that Kneser-Ney smoothing gives us better performance is by making a HMM model and comparing the performance of a variety of smoothing methods with the modified Kneser-Ney smoothing. It seems a settled empirial result that modified Kneser-Ney smoothing is the best smoothing method for language models, but that may not be the case for this task.

The way that I am testing the assumption that reinforcement learning gives us better performance is by comparing an HMM model with a Q-learning model and seeing their respective performances. I haven't gotten to this part yet, but I have more features. In addition to an unsmoothed 3-gram feature of note pitch values, I also have note pitch differentials (the difference between a note and the note before it), the and the variance statistic on pitch.

You can keep track of the development at github:

\url{https://github.com/howonlee/221proj}

\begin{thebibliography}{9}%no more than 9 references

\bibitem{BoulangerLewandowski12}
N Boulanger-Lewandowsky, Y. Bengio and P. Vincent, Modeling Temporal Dependencies in High-Dimensional Sequences: Application to Polyphonic Music Generation and Transcription, in Proceedings of the 29th International Conference on Machine Learning (ICML), 2012.

\bibitem{Rabiner}
L. Rabiner, A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition, in Proceeding of the IEEE, 1989.

\bibitem{Watkins}
C. Watkins, Technical Note on Q-Learning, in Machine Learning, 1992.

\bibitem{Rummery}
N. Taghipour, A. Kardan, A Hybrid Web Recommender System Based on Q-Learning, in the 8th ACM Sympsium on Applied Computing, 2008

\end{thebibliography}

\end{document}
